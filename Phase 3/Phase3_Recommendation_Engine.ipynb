{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Recommendation Engine\n",
    "\n",
    "## Study Resource Recommender\n",
    "\n",
    "**Objective:** Build the recommendation engine that:\n",
    "1. Takes student quiz results\n",
    "2. Predicts mastery level for each skill using ML model\n",
    "3. Identifies weak skills (needs_help)\n",
    "4. Recommends relevant YouTube videos\n",
    "\n",
    "---\n",
    "\n",
    "## Flow\n",
    "\n",
    "```\n",
    "Student Quiz Data ‚Üí ML Model ‚Üí Predict Mastery ‚Üí Find Weak Skills ‚Üí Match Videos ‚Üí Recommendations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Saved Models and Data from Phase 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from Phase 2\n",
    "best_model = joblib.load('best_model.pkl')\n",
    "print(\"‚úÖ Best model loaded!\")\n",
    "\n",
    "# Load scaler\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "print(\"‚úÖ Scaler loaded!\")\n",
    "\n",
    "# Load label encoder\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "print(\"‚úÖ Label encoder loaded!\")\n",
    "\n",
    "# Load feature configuration\n",
    "with open('feature_config.pkl', 'rb') as f:\n",
    "    feature_config = pickle.load(f)\n",
    "print(\"‚úÖ Feature config loaded!\")\n",
    "\n",
    "print(f\"\\nBest Model: {feature_config['best_model']}\")\n",
    "print(f\"Features: {len(feature_config['feature_columns'])}\")\n",
    "print(f\"Classes: {feature_config['label_classes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from Phase 1\n",
    "student_skill_df = pd.read_csv('student_skill_performance.csv')\n",
    "print(f\"‚úÖ Student skill performance loaded: {len(student_skill_df)} records\")\n",
    "\n",
    "skill_video_df = pd.read_csv('skill_video_mapping.csv')\n",
    "print(f\"‚úÖ Skill-video mapping loaded: {len(skill_video_df)} mappings\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample skill-video mappings:\")\n",
    "skill_video_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available skills with videos\n",
    "skills_with_videos = skill_video_df['skill_name'].unique()\n",
    "print(f\"Skills with video recommendations: {len(skills_with_videos)}\")\n",
    "print(\"\\nSample skills:\")\n",
    "for skill in list(skills_with_videos)[:10]:\n",
    "    print(f\"  - {skill}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Recommendation Engine Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyResourceRecommender:\n",
    "    \"\"\"\n",
    "    A recommendation engine that suggests YouTube videos based on student performance.\n",
    "    \n",
    "    Workflow:\n",
    "    1. Analyze student's quiz performance per skill\n",
    "    2. Predict mastery level using ML model\n",
    "    3. Identify weak skills (needs_help)\n",
    "    4. Recommend relevant YouTube videos\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, scaler, label_encoder, feature_config, skill_video_mapping):\n",
    "        \"\"\"\n",
    "        Initialize the recommender.\n",
    "        \n",
    "        Parameters:\n",
    "        - model: Trained ML model\n",
    "        - scaler: Fitted StandardScaler\n",
    "        - label_encoder: Fitted LabelEncoder\n",
    "        - feature_config: Dict with feature columns and settings\n",
    "        - skill_video_mapping: DataFrame mapping skills to videos\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.label_encoder = label_encoder\n",
    "        self.feature_columns = feature_config['feature_columns']\n",
    "        self.needs_scaling = feature_config.get('needs_scaling', True)\n",
    "        self.skill_video_mapping = skill_video_mapping\n",
    "        \n",
    "    def predict_mastery(self, student_features):\n",
    "        \"\"\"\n",
    "        Predict mastery level for given features.\n",
    "        \n",
    "        Parameters:\n",
    "        - student_features: DataFrame with feature values\n",
    "        \n",
    "        Returns:\n",
    "        - predictions: List of mastery levels\n",
    "        - probabilities: Array of probabilities per class\n",
    "        \"\"\"\n",
    "        # Ensure correct feature order\n",
    "        features = student_features[self.feature_columns].copy()\n",
    "        \n",
    "        # Scale if needed\n",
    "        if self.needs_scaling:\n",
    "            features_processed = self.scaler.transform(features)\n",
    "        else:\n",
    "            features_processed = features.values\n",
    "        \n",
    "        # Predict\n",
    "        predictions_encoded = self.model.predict(features_processed)\n",
    "        probabilities = self.model.predict_proba(features_processed)\n",
    "        \n",
    "        # Decode predictions\n",
    "        predictions = self.label_encoder.inverse_transform(predictions_encoded)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def get_videos_for_skill(self, skill_name, top_n=5):\n",
    "        \"\"\"\n",
    "        Get top videos for a specific skill.\n",
    "        \n",
    "        Parameters:\n",
    "        - skill_name: Name of the skill\n",
    "        - top_n: Number of videos to return\n",
    "        \n",
    "        Returns:\n",
    "        - DataFrame with video recommendations\n",
    "        \"\"\"\n",
    "        videos = self.skill_video_mapping[\n",
    "            self.skill_video_mapping['skill_name'] == skill_name\n",
    "        ].copy()\n",
    "        \n",
    "        if len(videos) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Sort by relevance (keyword_score) and popularity (views)\n",
    "        if 'keyword_score' in videos.columns and 'views' in videos.columns:\n",
    "            videos['ranking_score'] = (\n",
    "                videos['keyword_score'] * 0.6 + \n",
    "                (videos['views'] / videos['views'].max()) * 0.4\n",
    "            )\n",
    "            videos = videos.sort_values('ranking_score', ascending=False)\n",
    "        \n",
    "        return videos.head(top_n)\n",
    "    \n",
    "    def analyze_student(self, student_data):\n",
    "        \"\"\"\n",
    "        Analyze a student's performance across all skills.\n",
    "        \n",
    "        Parameters:\n",
    "        - student_data: DataFrame with student's performance per skill\n",
    "        \n",
    "        Returns:\n",
    "        - analysis: DataFrame with skills, predictions, and probabilities\n",
    "        \"\"\"\n",
    "        # Get predictions\n",
    "        predictions, probabilities = self.predict_mastery(student_data)\n",
    "        \n",
    "        # Create analysis DataFrame\n",
    "        analysis = student_data[['skill_name']].copy()\n",
    "        analysis['predicted_mastery'] = predictions\n",
    "        analysis['accuracy'] = student_data['accuracy'].values\n",
    "        \n",
    "        # Add probabilities\n",
    "        for i, label in enumerate(self.label_encoder.classes_):\n",
    "            analysis[f'prob_{label}'] = probabilities[:, i]\n",
    "        \n",
    "        # Add confidence (max probability)\n",
    "        analysis['confidence'] = probabilities.max(axis=1)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def get_recommendations(self, student_data, top_skills=5, videos_per_skill=3):\n",
    "        \"\"\"\n",
    "        Get video recommendations for a student based on their weak skills.\n",
    "        \n",
    "        Parameters:\n",
    "        - student_data: DataFrame with student's performance per skill\n",
    "        - top_skills: Number of weak skills to focus on\n",
    "        - videos_per_skill: Number of videos per skill\n",
    "        \n",
    "        Returns:\n",
    "        - recommendations: Dict with analysis and video recommendations\n",
    "        \"\"\"\n",
    "        # Analyze student\n",
    "        analysis = self.analyze_student(student_data)\n",
    "        \n",
    "        # Get weak skills (predicted as needs_help)\n",
    "        weak_skills = analysis[\n",
    "            analysis['predicted_mastery'] == 'needs_help'\n",
    "        ].sort_values('accuracy').head(top_skills)\n",
    "        \n",
    "        # Get learning skills (might also need some help)\n",
    "        learning_skills = analysis[\n",
    "            analysis['predicted_mastery'] == 'learning'\n",
    "        ].sort_values('accuracy').head(top_skills)\n",
    "        \n",
    "        # Get mastered skills\n",
    "        mastered_skills = analysis[\n",
    "            analysis['predicted_mastery'] == 'mastered'\n",
    "        ]\n",
    "        \n",
    "        # Get video recommendations for weak skills\n",
    "        video_recommendations = []\n",
    "        \n",
    "        for _, row in weak_skills.iterrows():\n",
    "            skill = row['skill_name']\n",
    "            videos = self.get_videos_for_skill(skill, top_n=videos_per_skill)\n",
    "            \n",
    "            if len(videos) > 0:\n",
    "                for _, video in videos.iterrows():\n",
    "                    video_recommendations.append({\n",
    "                        'skill_name': skill,\n",
    "                        'student_accuracy': row['accuracy'],\n",
    "                        'mastery_level': 'needs_help',\n",
    "                        'priority': 'HIGH',\n",
    "                        'video_title': video.get('video_title', 'N/A'),\n",
    "                        'video_id': video.get('video_id', 'N/A'),\n",
    "                        'views': video.get('views', 0),\n",
    "                        'likes': video.get('likes', 0)\n",
    "                    })\n",
    "        \n",
    "        # Add learning skills recommendations (lower priority)\n",
    "        for _, row in learning_skills.iterrows():\n",
    "            skill = row['skill_name']\n",
    "            videos = self.get_videos_for_skill(skill, top_n=2)  # Fewer videos\n",
    "            \n",
    "            if len(videos) > 0:\n",
    "                for _, video in videos.iterrows():\n",
    "                    video_recommendations.append({\n",
    "                        'skill_name': skill,\n",
    "                        'student_accuracy': row['accuracy'],\n",
    "                        'mastery_level': 'learning',\n",
    "                        'priority': 'MEDIUM',\n",
    "                        'video_title': video.get('video_title', 'N/A'),\n",
    "                        'video_id': video.get('video_id', 'N/A'),\n",
    "                        'views': video.get('views', 0),\n",
    "                        'likes': video.get('likes', 0)\n",
    "                    })\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(video_recommendations)\n",
    "        \n",
    "        # Summary\n",
    "        summary = {\n",
    "            'total_skills_analyzed': len(analysis),\n",
    "            'skills_mastered': len(mastered_skills),\n",
    "            'skills_learning': len(learning_skills),\n",
    "            'skills_need_help': len(weak_skills),\n",
    "            'videos_recommended': len(recommendations_df)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'summary': summary,\n",
    "            'skill_analysis': analysis,\n",
    "            'weak_skills': weak_skills,\n",
    "            'learning_skills': learning_skills,\n",
    "            'mastered_skills': mastered_skills,\n",
    "            'video_recommendations': recommendations_df\n",
    "        }\n",
    "    \n",
    "    def print_recommendations(self, recommendations):\n",
    "        \"\"\"\n",
    "        Pretty print the recommendations.\n",
    "        \"\"\"\n",
    "        summary = recommendations['summary']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä STUDENT ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n   Total Skills Analyzed: {summary['total_skills_analyzed']}\")\n",
    "        print(f\"   ‚úÖ Mastered: {summary['skills_mastered']}\")\n",
    "        print(f\"   üìö Learning: {summary['skills_learning']}\")\n",
    "        print(f\"   ‚ùå Needs Help: {summary['skills_need_help']}\")\n",
    "        print(f\"   üé¨ Videos Recommended: {summary['videos_recommended']}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚ùå SKILLS THAT NEED HELP (Priority: HIGH)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        weak = recommendations['weak_skills']\n",
    "        if len(weak) > 0:\n",
    "            for _, row in weak.iterrows():\n",
    "                print(f\"\\n   üìå {row['skill_name']}\")\n",
    "                print(f\"      Accuracy: {row['accuracy']:.1%}\")\n",
    "                print(f\"      Confidence: {row['confidence']:.1%}\")\n",
    "        else:\n",
    "            print(\"\\n   üéâ No skills need immediate help!\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üé¨ VIDEO RECOMMENDATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        videos = recommendations['video_recommendations']\n",
    "        if len(videos) > 0:\n",
    "            current_skill = None\n",
    "            for _, row in videos.iterrows():\n",
    "                if row['skill_name'] != current_skill:\n",
    "                    current_skill = row['skill_name']\n",
    "                    priority_icon = \"üî¥\" if row['priority'] == 'HIGH' else \"üü°\"\n",
    "                    print(f\"\\n   {priority_icon} {current_skill.upper()} (Accuracy: {row['student_accuracy']:.1%})\")\n",
    "                \n",
    "                print(f\"      ‚Ä¢ {row['video_title']}\")\n",
    "                if row['views'] > 0:\n",
    "                    print(f\"        Views: {row['views']:,}\")\n",
    "        else:\n",
    "            print(\"\\n   No video recommendations available.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "print(\"‚úÖ StudyResourceRecommender class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize the Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create recommender instance\n",
    "recommender = StudyResourceRecommender(\n",
    "    model=best_model,\n",
    "    scaler=scaler,\n",
    "    label_encoder=label_encoder,\n",
    "    feature_config=feature_config,\n",
    "    skill_video_mapping=skill_video_df\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Recommender initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test with Sample Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample student's data\n",
    "sample_student_id = student_skill_df['user_id'].iloc[0]\n",
    "print(f\"Testing with Student ID: {sample_student_id}\")\n",
    "\n",
    "# Get all skills for this student\n",
    "sample_student_data = student_skill_df[\n",
    "    student_skill_df['user_id'] == sample_student_id\n",
    "].copy()\n",
    "\n",
    "print(f\"Skills attempted: {len(sample_student_data)}\")\n",
    "sample_student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have all required features\n",
    "# Add engineered features if missing\n",
    "def add_engineered_features(df):\n",
    "    \"\"\"Add engineered features from Phase 2 if they don't exist.\"\"\"\n",
    "    \n",
    "    if 'efficiency_score' not in df.columns:\n",
    "        df['efficiency_score'] = df['total_correct'] / (df['total_hints_used'] + 1)\n",
    "    \n",
    "    if 'struggle_score' not in df.columns:\n",
    "        df['struggle_score'] = (\n",
    "            (1 - df['accuracy']) * 0.4 + \n",
    "            df['avg_hint_ratio'] * 0.3 + \n",
    "            (df['avg_attempts'] / df['avg_attempts'].max()) * 0.3\n",
    "        )\n",
    "    \n",
    "    if 'speed_score' not in df.columns:\n",
    "        df['speed_score'] = 1 - (df['avg_response_time'] / df['avg_response_time'].max()).clip(0, 1)\n",
    "    \n",
    "    if 'hint_dependency' not in df.columns:\n",
    "        df['hint_dependency'] = (df['avg_hint_ratio'] + df['pct_hint_first']) / 2\n",
    "    \n",
    "    if 'attempts_per_correct' not in df.columns:\n",
    "        df['attempts_per_correct'] = df['total_attempts'] / (df['total_correct'] + 1)\n",
    "    \n",
    "    # Handle NaN/Inf\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "    \n",
    "    return df\n",
    "\n",
    "sample_student_data = add_engineered_features(sample_student_data)\n",
    "print(\"‚úÖ Features prepared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recommendations for sample student\n",
    "recommendations = recommender.get_recommendations(\n",
    "    sample_student_data,\n",
    "    top_skills=5,\n",
    "    videos_per_skill=3\n",
    ")\n",
    "\n",
    "# Print recommendations\n",
    "recommender.print_recommendations(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test with Multiple Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 5 random students\n",
    "random_students = student_skill_df['user_id'].drop_duplicates().sample(5, random_state=42)\n",
    "\n",
    "print(\"Testing recommendations for 5 random students:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for student_id in random_students:\n",
    "    student_data = student_skill_df[student_skill_df['user_id'] == student_id].copy()\n",
    "    student_data = add_engineered_features(student_data)\n",
    "    \n",
    "    recs = recommender.get_recommendations(student_data, top_skills=3, videos_per_skill=2)\n",
    "    \n",
    "    print(f\"\\nüë§ Student ID: {student_id}\")\n",
    "    print(f\"   Skills: {recs['summary']['total_skills_analyzed']}\")\n",
    "    print(f\"   Mastered: {recs['summary']['skills_mastered']}\")\n",
    "    print(f\"   Need Help: {recs['summary']['skills_need_help']}\")\n",
    "    print(f\"   Videos Recommended: {recs['summary']['videos_recommended']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Function for New Quiz Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_quiz_results(quiz_results):\n",
    "    \"\"\"\n",
    "    Process raw quiz results into features for the recommender.\n",
    "    \n",
    "    Parameters:\n",
    "    - quiz_results: List of dicts with quiz attempt data\n",
    "      Each dict should have: skill_name, correct (0/1), hints_used, time_taken_sec\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame ready for recommendation engine\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(quiz_results)\n",
    "    \n",
    "    # Aggregate by skill\n",
    "    aggregated = df.groupby('skill_name').agg({\n",
    "        'correct': ['sum', 'count', 'mean'],\n",
    "        'hints_used': ['sum', 'mean'],\n",
    "        'time_taken_sec': 'mean',\n",
    "        'hints_available': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten columns\n",
    "    aggregated.columns = [\n",
    "        'skill_name', \n",
    "        'total_correct', 'total_attempts', 'accuracy',\n",
    "        'total_hints_used', 'avg_hint_count',\n",
    "        'avg_response_time',\n",
    "        'avg_hints_available'\n",
    "    ]\n",
    "    \n",
    "    # Calculate additional features\n",
    "    aggregated['avg_hint_ratio'] = (\n",
    "        aggregated['avg_hint_count'] / aggregated['avg_hints_available'].replace(0, 1)\n",
    "    ).clip(0, 1)\n",
    "    \n",
    "    aggregated['avg_attempts'] = aggregated['total_attempts'] / aggregated['total_attempts'].max()\n",
    "    aggregated['pct_hint_first'] = 0.3  # Default value\n",
    "    aggregated['difficulty_score'] = (1 - aggregated['accuracy']) * 0.7 + aggregated['avg_hint_ratio'] * 0.3\n",
    "    \n",
    "    # Add engineered features\n",
    "    aggregated = add_engineered_features(aggregated)\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "\n",
    "# Example: Simulate new quiz results\n",
    "new_quiz_results = [\n",
    "    # Skill: Fractions (struggling)\n",
    "    {'skill_name': 'fractions', 'correct': 0, 'hints_used': 3, 'hints_available': 3, 'time_taken_sec': 120},\n",
    "    {'skill_name': 'fractions', 'correct': 0, 'hints_used': 2, 'hints_available': 3, 'time_taken_sec': 90},\n",
    "    {'skill_name': 'fractions', 'correct': 1, 'hints_used': 2, 'hints_available': 3, 'time_taken_sec': 60},\n",
    "    {'skill_name': 'fractions', 'correct': 0, 'hints_used': 3, 'hints_available': 3, 'time_taken_sec': 100},\n",
    "    \n",
    "    # Skill: Addition (doing well)\n",
    "    {'skill_name': 'addition', 'correct': 1, 'hints_used': 0, 'hints_available': 3, 'time_taken_sec': 20},\n",
    "    {'skill_name': 'addition', 'correct': 1, 'hints_used': 0, 'hints_available': 3, 'time_taken_sec': 15},\n",
    "    {'skill_name': 'addition', 'correct': 1, 'hints_used': 0, 'hints_available': 3, 'time_taken_sec': 18},\n",
    "    {'skill_name': 'addition', 'correct': 1, 'hints_used': 1, 'hints_available': 3, 'time_taken_sec': 25},\n",
    "    \n",
    "    # Skill: Algebra (learning)\n",
    "    {'skill_name': 'algebra', 'correct': 1, 'hints_used': 1, 'hints_available': 3, 'time_taken_sec': 45},\n",
    "    {'skill_name': 'algebra', 'correct': 0, 'hints_used': 2, 'hints_available': 3, 'time_taken_sec': 60},\n",
    "    {'skill_name': 'algebra', 'correct': 1, 'hints_used': 1, 'hints_available': 3, 'time_taken_sec': 40},\n",
    "    {'skill_name': 'algebra', 'correct': 1, 'hints_used': 0, 'hints_available': 3, 'time_taken_sec': 35},\n",
    "]\n",
    "\n",
    "print(\"Sample quiz results processed:\")\n",
    "processed_quiz = process_quiz_results(new_quiz_results)\n",
    "processed_quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Simple API Functions for GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_recommendations_by_id(student_id, student_skill_df, recommender):\n",
    "    \"\"\"\n",
    "    Get recommendations for a student by their ID.\n",
    "    This function will be used by the GUI.\n",
    "    \n",
    "    Parameters:\n",
    "    - student_id: Student's user ID\n",
    "    - student_skill_df: Full student performance DataFrame\n",
    "    - recommender: StudyResourceRecommender instance\n",
    "    \n",
    "    Returns:\n",
    "    - dict with recommendations or error message\n",
    "    \"\"\"\n",
    "    # Check if student exists\n",
    "    if student_id not in student_skill_df['user_id'].values:\n",
    "        return {'error': f'Student ID {student_id} not found'}\n",
    "    \n",
    "    # Get student data\n",
    "    student_data = student_skill_df[student_skill_df['user_id'] == student_id].copy()\n",
    "    student_data = add_engineered_features(student_data)\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommendations = recommender.get_recommendations(\n",
    "        student_data,\n",
    "        top_skills=5,\n",
    "        videos_per_skill=3\n",
    "    )\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def get_all_student_ids(student_skill_df):\n",
    "    \"\"\"\n",
    "    Get list of all student IDs for dropdown in GUI.\n",
    "    \"\"\"\n",
    "    return student_skill_df['user_id'].unique().tolist()\n",
    "\n",
    "\n",
    "def get_skill_summary(recommendations):\n",
    "    \"\"\"\n",
    "    Get a simple summary for display.\n",
    "    \"\"\"\n",
    "    if 'error' in recommendations:\n",
    "        return recommendations\n",
    "    \n",
    "    analysis = recommendations['skill_analysis']\n",
    "    \n",
    "    return {\n",
    "        'mastered': analysis[analysis['predicted_mastery'] == 'mastered']['skill_name'].tolist(),\n",
    "        'learning': analysis[analysis['predicted_mastery'] == 'learning']['skill_name'].tolist(),\n",
    "        'needs_help': analysis[analysis['predicted_mastery'] == 'needs_help']['skill_name'].tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ API functions created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API function\n",
    "test_student_id = student_skill_df['user_id'].iloc[0]\n",
    "result = get_student_recommendations_by_id(test_student_id, student_skill_df, recommender)\n",
    "\n",
    "print(f\"API Test for Student {test_student_id}:\")\n",
    "print(f\"Summary: {result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Recommender for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything needed for deployment\n",
    "deployment_package = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': label_encoder,\n",
    "    'feature_config': feature_config,\n",
    "    'skill_video_mapping': skill_video_df\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open('recommender_package.pkl', 'wb') as f:\n",
    "    pickle.dump(deployment_package, f)\n",
    "\n",
    "print(\"‚úÖ Recommender package saved: recommender_package.pkl\")\n",
    "\n",
    "# Also save student data for the demo\n",
    "student_skill_df.to_csv('student_data_for_app.csv', index=False)\n",
    "print(\"‚úÖ Student data saved: student_data_for_app.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create recommender.py Module for GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the recommender.py file for the Streamlit app\n",
    "recommender_module = '''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "class StudyResourceRecommender:\n",
    "    \"\"\"\n",
    "    A recommendation engine that suggests YouTube videos based on student performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, scaler, label_encoder, feature_config, skill_video_mapping):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.label_encoder = label_encoder\n",
    "        self.feature_columns = feature_config[\\'feature_columns\\']\n",
    "        self.needs_scaling = feature_config.get(\\'needs_scaling\\', True)\n",
    "        self.skill_video_mapping = skill_video_mapping\n",
    "        \n",
    "    def predict_mastery(self, student_features):\n",
    "        features = student_features[self.feature_columns].copy()\n",
    "        \n",
    "        if self.needs_scaling:\n",
    "            features_processed = self.scaler.transform(features)\n",
    "        else:\n",
    "            features_processed = features.values\n",
    "        \n",
    "        predictions_encoded = self.model.predict(features_processed)\n",
    "        probabilities = self.model.predict_proba(features_processed)\n",
    "        predictions = self.label_encoder.inverse_transform(predictions_encoded)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def get_videos_for_skill(self, skill_name, top_n=5):\n",
    "        videos = self.skill_video_mapping[\n",
    "            self.skill_video_mapping[\\'skill_name\\'] == skill_name\n",
    "        ].copy()\n",
    "        \n",
    "        if len(videos) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        if \\'keyword_score\\' in videos.columns and \\'views\\' in videos.columns:\n",
    "            videos[\\'ranking_score\\'] = (\n",
    "                videos[\\'keyword_score\\'] * 0.6 + \n",
    "                (videos[\\'views\\'] / videos[\\'views\\'].max()) * 0.4\n",
    "            )\n",
    "            videos = videos.sort_values(\\'ranking_score\\', ascending=False)\n",
    "        \n",
    "        return videos.head(top_n)\n",
    "    \n",
    "    def analyze_student(self, student_data):\n",
    "        predictions, probabilities = self.predict_mastery(student_data)\n",
    "        \n",
    "        analysis = student_data[[\\'skill_name\\']].copy()\n",
    "        analysis[\\'predicted_mastery\\'] = predictions\n",
    "        analysis[\\'accuracy\\'] = student_data[\\'accuracy\\'].values\n",
    "        \n",
    "        for i, label in enumerate(self.label_encoder.classes_):\n",
    "            analysis[f\\'prob_{label}\\'] = probabilities[:, i]\n",
    "        \n",
    "        analysis[\\'confidence\\'] = probabilities.max(axis=1)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def get_recommendations(self, student_data, top_skills=5, videos_per_skill=3):\n",
    "        analysis = self.analyze_student(student_data)\n",
    "        \n",
    "        weak_skills = analysis[\n",
    "            analysis[\\'predicted_mastery\\'] == \\'needs_help\\'\n",
    "        ].sort_values(\\'accuracy\\').head(top_skills)\n",
    "        \n",
    "        learning_skills = analysis[\n",
    "            analysis[\\'predicted_mastery\\'] == \\'learning\\'\n",
    "        ].sort_values(\\'accuracy\\').head(top_skills)\n",
    "        \n",
    "        mastered_skills = analysis[\n",
    "            analysis[\\'predicted_mastery\\'] == \\'mastered\\'\n",
    "        ]\n",
    "        \n",
    "        video_recommendations = []\n",
    "        \n",
    "        for _, row in weak_skills.iterrows():\n",
    "            skill = row[\\'skill_name\\']\n",
    "            videos = self.get_videos_for_skill(skill, top_n=videos_per_skill)\n",
    "            \n",
    "            if len(videos) > 0:\n",
    "                for _, video in videos.iterrows():\n",
    "                    video_recommendations.append({\n",
    "                        \\'skill_name\\': skill,\n",
    "                        \\'student_accuracy\\': row[\\'accuracy\\'],\n",
    "                        \\'mastery_level\\': \\'needs_help\\',\n",
    "                        \\'priority\\': \\'HIGH\\',\n",
    "                        \\'video_title\\': video.get(\\'video_title\\', \\'N/A\\'),\n",
    "                        \\'video_id\\': video.get(\\'video_id\\', \\'N/A\\'),\n",
    "                        \\'views\\': video.get(\\'views\\', 0),\n",
    "                        \\'likes\\': video.get(\\'likes\\', 0)\n",
    "                    })\n",
    "        \n",
    "        for _, row in learning_skills.iterrows():\n",
    "            skill = row[\\'skill_name\\']\n",
    "            videos = self.get_videos_for_skill(skill, top_n=2)\n",
    "            \n",
    "            if len(videos) > 0:\n",
    "                for _, video in videos.iterrows():\n",
    "                    video_recommendations.append({\n",
    "                        \\'skill_name\\': skill,\n",
    "                        \\'student_accuracy\\': row[\\'accuracy\\'],\n",
    "                        \\'mastery_level\\': \\'learning\\',\n",
    "                        \\'priority\\': \\'MEDIUM\\',\n",
    "                        \\'video_title\\': video.get(\\'video_title\\', \\'N/A\\'),\n",
    "                        \\'video_id\\': video.get(\\'video_id\\', \\'N/A\\'),\n",
    "                        \\'views\\': video.get(\\'views\\', 0),\n",
    "                        \\'likes\\': video.get(\\'likes\\', 0)\n",
    "                    })\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(video_recommendations)\n",
    "        \n",
    "        summary = {\n",
    "            \\'total_skills_analyzed\\': len(analysis),\n",
    "            \\'skills_mastered\\': len(mastered_skills),\n",
    "            \\'skills_learning\\': len(learning_skills),\n",
    "            \\'skills_need_help\\': len(weak_skills),\n",
    "            \\'videos_recommended\\': len(recommendations_df)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \\'summary\\': summary,\n",
    "            \\'skill_analysis\\': analysis,\n",
    "            \\'weak_skills\\': weak_skills,\n",
    "            \\'learning_skills\\': learning_skills,\n",
    "            \\'mastered_skills\\': mastered_skills,\n",
    "            \\'video_recommendations\\': recommendations_df\n",
    "        }\n",
    "\n",
    "\n",
    "def load_recommender(package_path=\\'recommender_package.pkl\\'):\n",
    "    \"\"\"Load the recommender from saved package.\"\"\"\n",
    "    with open(package_path, \\'rb\\') as f:\n",
    "        package = pickle.load(f)\n",
    "    \n",
    "    return StudyResourceRecommender(\n",
    "        model=package[\\'model\\'],\n",
    "        scaler=package[\\'scaler\\'],\n",
    "        label_encoder=package[\\'label_encoder\\'],\n",
    "        feature_config=package[\\'feature_config\\'],\n",
    "        skill_video_mapping=package[\\'skill_video_mapping\\']\n",
    "    )\n",
    "\n",
    "\n",
    "def add_engineered_features(df):\n",
    "    \"\"\"Add engineered features if they don\\'t exist.\"\"\"\n",
    "    \n",
    "    if \\'efficiency_score\\' not in df.columns:\n",
    "        df[\\'efficiency_score\\'] = df[\\'total_correct\\'] / (df[\\'total_hints_used\\'] + 1)\n",
    "    \n",
    "    if \\'struggle_score\\' not in df.columns:\n",
    "        df[\\'struggle_score\\'] = (\n",
    "            (1 - df[\\'accuracy\\']) * 0.4 + \n",
    "            df[\\'avg_hint_ratio\\'] * 0.3 + \n",
    "            (df[\\'avg_attempts\\'] / df[\\'avg_attempts\\'].max()) * 0.3\n",
    "        )\n",
    "    \n",
    "    if \\'speed_score\\' not in df.columns:\n",
    "        df[\\'speed_score\\'] = 1 - (df[\\'avg_response_time\\'] / df[\\'avg_response_time\\'].max()).clip(0, 1)\n",
    "    \n",
    "    if \\'hint_dependency\\' not in df.columns:\n",
    "        df[\\'hint_dependency\\'] = (df[\\'avg_hint_ratio\\'] + df[\\'pct_hint_first\\']) / 2\n",
    "    \n",
    "    if \\'attempts_per_correct\\' not in df.columns:\n",
    "        df[\\'attempts_per_correct\\'] = df[\\'total_attempts\\'] / (df[\\'total_correct\\'] + 1)\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "    \n",
    "    return df\n",
    "'''\n",
    "\n",
    "with open('recommender.py', 'w') as f:\n",
    "    f.write(recommender_module)\n",
    "\n",
    "print(\"‚úÖ recommender.py module created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 3 COMPLETE - RECOMMENDATION ENGINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED:\")\n",
    "print(\"   1. Built StudyResourceRecommender class\")\n",
    "print(\"   2. Integrated ML model with video recommendations\")\n",
    "print(\"   3. Created prediction and analysis functions\")\n",
    "print(\"   4. Tested with sample students\")\n",
    "print(\"   5. Created API functions for GUI\")\n",
    "print(\"   6. Saved deployment package\")\n",
    "\n",
    "print(\"\\nüìÅ FILES CREATED:\")\n",
    "print(\"   - recommender_package.pkl (all models + data)\")\n",
    "print(\"   - student_data_for_app.csv (student data for demo)\")\n",
    "print(\"   - recommender.py (module for Streamlit app)\")\n",
    "\n",
    "print(\"\\nüîÑ RECOMMENDATION FLOW:\")\n",
    "print(\"   Student ID ‚Üí Get Performance Data ‚Üí ML Prediction ‚Üí\")\n",
    "print(\"   Identify Weak Skills ‚Üí Match Videos ‚Üí Return Recommendations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT: Phase 4 - Build GUI with Streamlit & Deploy\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps (Phase 4)\n",
    "\n",
    "1. Create Streamlit app (app.py)\n",
    "2. Design user interface:\n",
    "   - Student ID input / dropdown\n",
    "   - Skill analysis dashboard\n",
    "   - Video recommendations display\n",
    "3. Deploy to Streamlit Cloud or HuggingFace Spaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
